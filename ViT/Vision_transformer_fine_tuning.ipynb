{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"14kJ4RfuZ6J-3ducuB7dv3YCqm5aNTf1l","authorship_tag":"ABX9TyMG6zlGmwU7/QqNLfYp/UvH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install patool\n","!pip install timm\n","!pip install pydicom\n","!pip install pytorch-ignite"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0YN3hBRncVdq","executionInfo":{"status":"ok","timestamp":1692592086118,"user_tz":-420,"elapsed":23377,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"53f2ca92-46cf-4e2e-8f11-79e47c322c91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting patool\n","  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m61.4/77.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: patool\n","Successfully installed patool-1.12\n","Collecting timm\n","  Downloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Collecting huggingface-hub (from timm)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","Installing collected packages: safetensors, huggingface-hub, timm\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 timm-0.9.5\n","Collecting pydicom\n","  Downloading pydicom-2.4.3-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydicom\n","Successfully installed pydicom-2.4.3\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.12-py3-none-any.whl (266 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (2.0.1+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3,>=1.3->pytorch-ignite) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3,>=1.3->pytorch-ignite) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n","Installing collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.4.12\n"]}]},{"cell_type":"code","source":["import patoolib\n","\n","# Path to the RAR file (change this to your file's path)\n","rar_file_path = \"/content/drive/MyDrive/Colab Notebooks/pratice/archive.zip\"\n","\n","# Directory to extract the contents to\n","extracted_dir = \"/content/drive/MyDrive/Colab Notebooks/pratice/clother\"\n","\n","# Extract the RAR file to the specified directory\n","patoolib.extract_archive(rar_file_path, outdir=extracted_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"6ZyRfSeYc4ER","executionInfo":{"status":"ok","timestamp":1692493299505,"user_tz":-420,"elapsed":142319,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"11993126-5922-4a37-aef1-2b8793887be1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["patool: Extracting /content/drive/MyDrive/Colab Notebooks/pratice/archive.zip ...\n","patool: running /usr/bin/7z x \"-o/content/drive/MyDrive/Colab Notebooks/pratice/clother\" -- \"/content/drive/MyDrive/Colab Notebooks/pratice/archive.zip\"\n","patool: ... /content/drive/MyDrive/Colab Notebooks/pratice/archive.zip extracted to `/content/drive/MyDrive/Colab Notebooks/pratice/clother'.\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab Notebooks/pratice/clother'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mJ6svVZ4cS-q"},"outputs":[],"source":["import os\n","import torch\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, random_split, DataLoader\n","from PIL import Image\n","import torchvision.models as models\n","from tqdm.notebook import tqdm\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torchvision.utils import make_grid\n","\n","import os\n","import re\n","import requests\n","\n","import matplotlib.pyplot as plt\n","import timm"]},{"cell_type":"code","source":["print(\"Available Vision Transformer Models: \")\n","timm.list_models(\"vit*\")"],"metadata":{"id":"Fz5P9BW3_Tb5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = '/content/drive/MyDrive/Colab Notebooks/pratice/clother'\n","print(os.listdir(data_dir))\n","print(len(os.listdir(data_dir)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z77RO0Vddlba","executionInfo":{"status":"ok","timestamp":1692592094910,"user_tz":-420,"elapsed":508,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"1896619f-f2a6-4100-d779-cecd553f9521"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['black_dress', 'black_pants', 'black_shirt', 'black_shoes', 'black_shorts', 'blue_dress', 'blue_pants', 'blue_shirt', 'blue_shoes', 'blue_shorts', 'brown_pants', 'brown_shoes', 'brown_shorts', 'green_pants', 'green_shirt', 'green_shoes', 'green_shorts', 'red_dress', 'red_pants', 'red_shoes', 'white_dress', 'white_pants', 'white_shoes', 'white_shorts']\n","24\n"]}]},{"cell_type":"code","source":["def get_path_names(dir):\n","  images = []\n","  for path, subdirs, files in os.walk(data_dir):\n","    for name in files:\n","      #print(os.path.join(path, name))\n","      images.append(os.path.join(path, name))\n","  return images"],"metadata":{"id":"gmmgORFYdtbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes = ['black', 'blue', 'brown', 'green', 'white', 'red', 'dress', 'pants', 'shorts', 'shoes', 'shirt']\n","len(classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYQm2_yRe26I","executionInfo":{"status":"ok","timestamp":1692592099908,"user_tz":-420,"elapsed":357,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"0cd9b6f1-c9fa-47ce-ab93-08ace2ff3a8d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def encode_label(label, classes_list = classes): #encoding the classes into a tensor of shape (11) with 0 and 1s.\n","    target = torch.zeros(11)\n","    for l in label:\n","      idx = classes_list.index(l)\n","      target[idx] = 1\n","    return target\n","\n","\n","def decode_target(target, threshold=0.5): #decoding the prediction tensors of 0s and 1s into text form\n","    result = []\n","    for i, x in enumerate(target):\n","        if (x >= threshold):\n","          result.append(classes[i])\n","    return ' '.join(result)"],"metadata":{"id":"VjopF98-e4sI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class myDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.transform = transform\n","        self.root_dir = root_dir\n","        self.images = get_path_names(root_dir)\n","\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.images[idx]\n","        img = Image.open(img_path)\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        label = re.findall(r'\\w+\\_\\w+', img_path)[0].split('_')\n","\n","        return img, encode_label(label)"],"metadata":{"id":"RtEhJ8sfe4uI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # mean and std values of the Imagenet Dataset so that pretrained models could also be used\n","\n","\n","\n","transform = T.Compose([\n","    T.Resize((224, 224)),\n","    T.RandomCrop(224),\n","    T.RandomHorizontalFlip(),\n","    T.RandomRotation(2),\n","    T.ToTensor(),\n","    T.Normalize(*imagenet_stats)\n","])\n"],"metadata":{"id":"YfNmfgFXf9y3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label = re.findall(r'\\w+\\_\\w+', '/content/drive/MyDrive/Colab Notebooks/pratice/clother/black_pants/00a2c27ab296e6c2f7220f38c68ef3d11bdd25bd.jpg')[0].split('_')"],"metadata":{"id":"8CtOibt6gekH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QlZhSRoAhwDs","executionInfo":{"status":"ok","timestamp":1692494400035,"user_tz":-420,"elapsed":3,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"f3d45e47-9b35-497d-bd07-eeb224bbbccb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['black', 'pants']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["a=encode_label(label)"],"metadata":{"id":"UA6LHRGkh4Qi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZA5GrExDh5IU","executionInfo":{"status":"ok","timestamp":1692494437646,"user_tz":-420,"elapsed":6,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"126ca1c5-7b9c-4a5a-d74d-7ed6b829d9bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["dataset = myDataset(data_dir, transform = transform)\n","len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsHBBOFFjWcY","executionInfo":{"status":"ok","timestamp":1692592114787,"user_tz":-420,"elapsed":5613,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"a4e07258-aabe-4743-cf61-a20c16493b0e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11385"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["def denorm(img_tensors):\n","    return img_tensors * imagenet_stats[1][0] + imagenet_stats[0][0]\n","\n","def show_example(img,label):\n","  plt.imshow(denorm(img).permute(1,2,0))\n","  print(\"Label:\", decode_target(label))\n","  print()\n","  print(label)\n"],"metadata":{"id":"HNXTLyn4jYm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_percent = int(0.15 * len(dataset))\n","train_size = len(dataset) - val_percent\n","val_size = len(dataset) - train_size\n","train_size, val_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7jc5_PSjqU8","executionInfo":{"status":"ok","timestamp":1692592117540,"user_tz":-420,"elapsed":3,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"2d5535da-283b-4956-a2e0-45eee79322bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9678, 1707)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["train_ds, val_ds = random_split(dataset, [train_size, val_size]) #splitting the dataset for training and validation.\n","len(train_ds), len(val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8o1dNldAj1T2","executionInfo":{"status":"ok","timestamp":1692592119217,"user_tz":-420,"elapsed":2,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"0d3a591a-3240-4a8e-e7b8-84788d604fed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9678, 1707)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["batch_size = 64\n","train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n","val_loader = DataLoader(val_ds, batch_size * 2)"],"metadata":{"id":"W9a_gfxkj5Lo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","\n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl:\n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","device = get_default_device()\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44_IbiWnkHth","executionInfo":{"status":"ok","timestamp":1692592122917,"user_tz":-420,"elapsed":6,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"ea3374c8-5976-4caa-933e-03b564916d4d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["train_dl = DeviceDataLoader(train_loader, device)\n","val_dl = DeviceDataLoader(val_loader, device)"],"metadata":{"id":"_HqNztZGkJZ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ViTBase16(nn.Module):\n","    def __init__(self, n_classes):\n","\n","        super(ViTBase16, self).__init__()\n","\n","        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n","\n","\n","        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n","        self.output = nn.Sigmoid()\n","    def forward(self, x):\n","        x = self.model(x)\n","\n","        x = self.output(x)\n","        return x\n"],"metadata":{"id":"BBej2GN_kOc2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ViTBase16(11)\n","model.to('cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VGNm0Z4lwn_","executionInfo":{"status":"ok","timestamp":1692592153838,"user_tz":-420,"elapsed":3018,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"d8e3e6f6-47ef-4c32-dfb8-5a098eee836a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ViTBase16(\n","  (model): VisionTransformer(\n","    (patch_embed): PatchEmbed(\n","      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","      (norm): Identity()\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (patch_drop): Identity()\n","    (norm_pre): Identity()\n","    (blocks): Sequential(\n","      (0): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (1): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (2): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (3): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (4): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (5): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (6): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (7): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (8): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (9): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (10): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","      (11): Block(\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): Attention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (q_norm): Identity()\n","          (k_norm): Identity()\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls1): Identity()\n","        (drop_path1): Identity()\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (act): GELU(approximate='none')\n","          (drop1): Dropout(p=0.0, inplace=False)\n","          (norm): Identity()\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (drop2): Dropout(p=0.0, inplace=False)\n","        )\n","        (ls2): Identity()\n","        (drop_path2): Identity()\n","      )\n","    )\n","    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","    (fc_norm): Identity()\n","    (head_drop): Dropout(p=0.0, inplace=False)\n","    (head): Linear(in_features=768, out_features=11, bias=True)\n","  )\n","  (output): Sigmoid()\n",")"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["from ignite.contrib.handlers import ProgressBar\n","from ignite.metrics import Accuracy,Loss, RunningAverage\n","from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n"],"metadata":{"id":"lz90u6GKlgyM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"],"metadata":{"id":"2Kw1ZUrblr7u","executionInfo":{"status":"error","timestamp":1692592133738,"user_tz":-420,"elapsed":4,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"c11cfd6f-9959-4407-ceb9-4970891b96ec"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-99b68afc77b6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":["val_metrics = {\n","    \"bce\": Loss(criterion),\n","\n","}"],"metadata":{"id":"Wt0Uplrzygqh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ignite.metrics import MultiLabelAccuracy"],"metadata":{"id":"-aBkfpqGqK6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n","evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n"],"metadata":{"id":"CD3G0m-oluCv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_loss = float('inf')\n","\n","# RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n","\n","# pbar = ProgressBar()\n","# pbar.attach(trainer)\n","\n","\n","@trainer.on(Events.ITERATION_COMPLETED(every=50))\n","def log_training_loss(engine):\n","    print(f\"Epoch {engine.state.epoch} - Iteration {engine.state.iteration} - Loss: {engine.state.output:.4f}\")\n","\n","@trainer.on(Events.EPOCH_COMPLETED)\n","def run_evaluation(engine):\n","    global best_loss\n","    evaluator.run(val_dl)\n","\n","    metrics = evaluator.state.metrics\n","    loss = metrics['bce']\n","    # acc= metrics['acc']\n","    print(f\"Validation Results - Epoch: {engine.state.epoch} - Loss: {loss:.4f} \" )\n","    if loss < best_loss:\n","        best_loss = loss\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/pratice/ViT.pth')\n","\n","trainer.add_event_handler(Events.EPOCH_COMPLETED, run_evaluation)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMcipBXymAmW","executionInfo":{"status":"ok","timestamp":1692589240203,"user_tz":-420,"elapsed":1039,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"dec50a44-4c03-4f0b-addb-78ebbb6e003c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<ignite.engine.events.RemovableEventHandle at 0x7b0f0b3a2200>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["trainer.run(train_dl, max_epochs=3)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"obZFg9NZmCW3","outputId":"e7c635cd-66a7-4ef2-f1b7-bcfb619eaeb8","executionInfo":{"status":"error","timestamp":1692591518112,"user_tz":-420,"elapsed":2274781,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 - Iteration 100 - Loss: 0.3939\n","Validation Results - Epoch: 1 - Loss: 0.3397 \n","Validation Results - Epoch: 1 - Loss: 0.3401 \n","Epoch 2 - Iteration 200 - Loss: 0.2837\n","Epoch 2 - Iteration 300 - Loss: 0.2766\n","Validation Results - Epoch: 2 - Loss: 0.3129 \n","Validation Results - Epoch: 2 - Loss: 0.3151 \n"]},{"output_type":"stream","name":"stderr","text":["ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-3c1443286f57>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterrupt_resume_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_legacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_as_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    957\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                     \u001b[0mepoch_time_taken\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset_as_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m                     \u001b[0;31m# time is available for handlers but must be updated after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_terminate_or_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_terminate_or_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ignite/engine/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y, y_pred, loss)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mprepare_batch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mmodel_transform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0moutput_transform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mamp_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def predict_image(model, image_path, threshold=0.5):\n","    # Load and preprocess the image\n","    img = Image.open(image_path)\n","    img = transform(img).unsqueeze(0).to(device)  # Preprocess and move to the device\n","\n","    # Make predictions\n","    model.eval()  # Set the model to evaluation mode\n","    with torch.no_grad():\n","        predictions = model(img)  # Get the model's outputs\n","\n","    # Apply threshold and decode predictions\n","    decoded_predictions = decode_target((predictions > threshold).squeeze().cpu().numpy())\n","\n","    return decoded_predictions\n","\n","# Load the trained model\n","model_path = '/content/drive/MyDrive/Colab Notebooks/pratice/ViT.pth'\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model.to(device)\n","model.eval()\n","\n","# Path to the image you want to predict\n"],"metadata":{"id":"ZJg2vGlfUEcI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","# Initialize lists to store predictions and targets\n","all_predictions = []\n","all_targets = []\n","\n","# Iterate through the validation data loader\n","with torch.no_grad():\n","    for images, labels in val_dl:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass to get predictions\n","        predictions = model(images)\n","\n","        all_predictions.append(predictions.cpu())\n","        all_targets.append(labels.cpu())\n","\n","# Concatenate predictions and targets\n","all_predictions = torch.cat(all_predictions, dim=0)\n","all_targets = torch.cat(all_targets, dim=0)\n","\n","# Apply threshold to predictions\n","threshold = 0.5\n","binary_predictions = (all_predictions > threshold).float()\n","\n","# Calculate F1 score\n","f1 = f1_score(all_targets, binary_predictions, average='samples')\n","\n","print(f\"F1 Score on Validation Data: {f1:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MWSXKlPTWLOH","executionInfo":{"status":"ok","timestamp":1692595012793,"user_tz":-420,"elapsed":1179711,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"33d27318-091e-490f-c1f0-0ff3fdb1ab96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score on Validation Data: 0.5563\n"]}]},{"cell_type":"code","source":["def decode_target(target, threshold=0.5): #decoding the prediction tensors of 0s and 1s into text form\n","    result = []\n","    for i, x in enumerate(target):\n","        if (x >= threshold):\n","          result.append(classes[i])\n","    return ' '.join(result)"],"metadata":{"id":"M4i-4xPgcDr9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path_to_predict = '/content/drive/MyDrive/Colab Notebooks/pratice/clother/blue_dress/784067f91cfd1a760e2f08fefe60b0618fd34705.jpg'\n","\n","# Call the prediction function\n","# predicted_labels = predict_image(model, image_path_to_predict)\n","img = Image.open(image_path_to_predict)\n","img = transform(img).unsqueeze(0).to(device)  # Preprocess and move to the device\n","\n","    # Make predictions\n","model.eval()  # Set the model to evaluation mode\n","with torch.no_grad():\n","      predictions = model(img)  # Get the model's outputs\n","\n","print(\"Predicted Labels:\", predictions[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nEwCL0SUwHA","executionInfo":{"status":"ok","timestamp":1692593784264,"user_tz":-420,"elapsed":1016,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"f2883b53-48c3-49a7-a931-345102dd1a7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Labels: tensor([1.7353e-02, 9.6098e-01, 8.5206e-04, 1.6677e-03, 1.9635e-02, 3.7194e-03,\n","        1.6788e-01, 1.0253e-01, 5.4331e-02, 3.9212e-01, 1.0148e-01])\n"]}]},{"cell_type":"code","source":["decode_target(predictions[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"U0N7-ql4cGzE","executionInfo":{"status":"ok","timestamp":1692593786769,"user_tz":-420,"elapsed":305,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"d4682614-5e5e-4637-c3b7-fd6d8d6445ef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'blue'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["['black', 'blue', 'brown', 'green', 'white', 'red', 'dress', 'pants', 'shorts', 'shoes', 'shirt']"],"metadata":{"id":"Dj3dvzimYOzi"}},{"cell_type":"code","source":["# Path to the image you want to predict\n","image_path_to_predict = '/content/drive/MyDrive/Colab Notebooks/pratice/clother/blue_dress/19dec6751c0f3ad362512021bc298558c0cca3c2.jpg'\n","\n","# Call the prediction function\n","predicted_labels = predict_image(model, image_path_to_predict)\n","\n","print(\"Predicted Labels:\", predicted_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nyr2Y05tUYM5","executionInfo":{"status":"ok","timestamp":1692593669146,"user_tz":-420,"elapsed":1607,"user":{"displayName":"Xuan Loc","userId":"17380094692041402636"}},"outputId":"0dd50544-4d88-426d-9a3e-3bee31a643ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Labels: blue\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm"],"metadata":{"id":"B32A4-kQnxCb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Available Vision Transformer Models: \")\n","timm.list_models(\"vit*\")"],"metadata":{"id":"dhame0Rs6v5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda'\n","import torch, gc\n","import os\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"ynv0KBDanfEe"},"execution_count":null,"outputs":[]}]}